# config/interactive_test.yaml
# A minimal configuration to test the new DisentangledASLNet and two-stage
# training curriculum in an interactive HPC session (~15 mins).

training:
  # === NEW: Specify the new model and training strategy ===
  model_class_name: "DisentangledASLNet"
  training_stages: ["ATT-only", "CBF-tuning"] # This flag activates your new curriculum

  # --- Key parameters for a fast run ---
  batch_size: 512
  n_ensembles: 1                # Only one model for a quick test
  validation_steps_per_epoch: 5 # Get validation feedback quickly
  
  # --- Stage 1: ATT-only (a few minutes) ---
  n_epochs_stage1: 2
  
  # --- Stage 2: CBF-tuning (a few minutes) ---
  n_epochs_stage2: 2

  # --- Architecture & Regularization (use proven values) ---
  hidden_sizes: [256, 128, 64]
  dropout_rate: 0.1
  weight_decay: 0.00001
  learning_rate_att: 0.001
  norm_type: "batch"

data:
  # This test runs on-the-fly, so we don't need the huge offline dataset
  use_offline_dataset: false
  offline_dataset_path: null
  pld_values: [500, 1000, 1500, 2000, 2500, 3000]
  num_samples: 1000 # For quick norm_stats calculation if needed

# --- Other required parameters ---
simulation:
  T1_artery: 1850.0
  T_tau: 1800.0
  T2_factor: 1.0
  alpha_BS1: 1.0
  alpha_PCASL: 0.85
  alpha_VSASL: 0.56

wandb:
  wandb_project: "asl-multiverse-interactive-tests"
  wandb_entity: null