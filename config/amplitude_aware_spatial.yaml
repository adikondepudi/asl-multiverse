# =============================================================================
# AMPLITUDE-AWARE SPATIAL ASL NETWORK CONFIGURATION
# =============================================================================
# This configuration trains the AmplitudeAwareSpatialASLNet which preserves
# signal amplitude information for accurate CBF estimation.
#
# Key differences from production_model_v1:
# 1. Uses AmplitudeAwareSpatialASLNet instead of SpatialASLNet
# 2. Enables physics loss (dc_weight > 0) for self-supervision
# 3. No per-curve normalization (amplitude must be preserved)
# =============================================================================

# --- MODEL ARCHITECTURE ---
training:
  model_class_name: AmplitudeAwareSpatialASLNet  # Amplitude-preserving architecture

  # Network capacity (same as production_v1)
  hidden_sizes: [32, 64, 128, 256]
  dropout_rate: 0.1
  norm_type: group  # GroupNorm in spatial path (OK because amplitude path preserves info)

  # Amplitude-aware features
  use_film_at_bottleneck: true   # FiLM modulation at bottleneck
  use_film_at_decoder: true      # FiLM modulation at decoder layers
  use_amplitude_output_modulation: true  # Direct amplitude -> CBF scaling

  # Loss configuration
  loss_type: l1                   # MAE loss
  dc_weight: 0.1                  # ENABLE physics loss for CBF self-supervision
  variance_weight: 0.1            # Prevents variance collapse

  # Target scaling (same as production)
  att_scale: 0.033
  cbf_weight: 1.0
  att_weight: 1.0

  # Uncertainty bounds
  log_var_cbf_min: -5.0
  log_var_cbf_max: 10.0
  log_var_att_min: -5.0
  log_var_att_max: 14.0

  # Training parameters
  learning_rate: 0.0001
  weight_decay: 0.0001
  batch_size: 32                  # Reduced for additional complexity
  n_epochs: 200
  n_ensembles: 5

  # Performance optimizations
  use_amp: true
  use_tf32: true
  use_compile: false              # Disable for debugging; enable for production
  cudnn_benchmark: true
  num_workers: 8
  pin_memory: true

  # Early stopping
  early_stopping_patience: 25
  early_stopping_min_delta: 0.0
  validation_steps_per_epoch: 50

# --- DATA CONFIGURATION ---
data:
  use_offline_dataset: true
  offline_dataset_path: asl_spatial_dataset_200k
  num_samples_to_load: 200000

  # PLD values (ms)
  pld_values: [500, 1000, 1500, 2000, 2500, 3000]

  # CRITICAL: Use global_scale to preserve amplitude
  # The amplitude-aware network REQUIRES non-normalized inputs
  normalization_mode: global_scale
  global_scale_factor: 10.0       # Scale to NN-friendly range

  # Noise model
  noise_type: rician              # MRI-correct magnitude noise

  # Active noise components
  data_noise_components:
    - thermal
    - physio
    - drift

# --- NOISE ENGINE CONFIGURATION ---
noise_config:
  snr_range: [2.0, 25.0]
  physio_amp_range: [0.03, 0.15]
  physio_freq_range: [0.5, 2.0]
  drift_range: [-0.03, 0.03]
  spike_probability: 0.02
  spike_magnitude_range: [2.0, 5.0]

# --- PHYSICS PARAMETERS ---
simulation:
  T1_artery: 1850.0
  T_tau: 1800.0
  alpha_PCASL: 0.85
  alpha_VSASL: 0.56
  T2_factor: 1.0
  alpha_BS1: 1.0

  # Domain randomization for generalization
  domain_randomization:
    enabled: true
    T1_artery_range: [1550.0, 2150.0]
    alpha_PCASL_range: [0.75, 0.95]
    alpha_VSASL_range: [0.40, 0.70]
    T_tau_perturb: 0.10

# --- LOGGING ---
wandb:
  wandb_project: asl-amplitude-aware
  wandb_entity: adikondepudi

# --- METADATA ---
_experiment:
  name: amplitude_aware_v1
  description: |
    Amplitude-Aware Spatial ASL Network with direct amplitude-to-CBF pathway.
    Key innovations:
    1. AmplitudeFeatureExtractor preserves signal amplitude before GroupNorm
    2. FiLM conditioning injects amplitude into spatial features
    3. Direct amplitude scaling on CBF output
    4. Physics loss enabled for self-supervision
  hypothesis: |
    By preserving amplitude information through a dedicated pathway, the network
    will achieve accurate CBF estimation that scales correctly with signal amplitude,
    unlike the standard U-Net which is amplitude-invariant due to GroupNorm.
