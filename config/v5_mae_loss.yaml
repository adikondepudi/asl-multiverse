# Configuration for MAE-based loss training (RECOMMENDED)
# This config forces the model to predict accurately by using MAE as primary loss
# instead of NLL which allows the model to "cheat" by predicting high uncertainty

training:
  # === NEW: Loss Mode Configuration ===
  # Options: 'mae_only', 'mse_only', 'nll_only', 'mae_nll', 'mse_nll'
  loss_mode: "mae_only"  # Forces accurate predictions, no uncertainty hedging
  mae_weight: 1.0        # Weight for MAE component
  nll_weight: 0.0        # NLL disabled in mae_only mode

  # Loss weights for CBF vs ATT (both important)
  loss_weight_cbf: 1.0
  loss_weight_att: 1.0

  # No log_var regularization needed with mae_only
  loss_log_var_reg_lambda: 0.0

  # Training parameters
  learning_rate: 0.001
  hidden_sizes: [128, 64, 32]
  dropout_rate: 0.1
  n_ensembles: 3
  training_epochs: 50
  batch_size: 512
  early_stopping_patience: 15

  # Architecture
  encoder_type: "physics_processor"
  transformer_d_model_focused: 32
  transformer_nhead_model: 4

data:
  dataset_path: "asl_clean_library_10M"
  pld_values: [500, 1000, 1500, 2000, 2500, 3000]
  active_features: ["mean", "std", "peak", "t1_artery"]
  data_noise_components: ["thermal"]

  # Normalization
  noise_type: "gaussian"
  normalization_mode: "per_curve"

simulation:
  T1_artery: 1650.0  # 3T consensus (Alsop 2015)
  T_tau: 1800.0
  alpha_PCASL: 0.85
  alpha_VSASL: 0.56

noise_config:
  snr_range: [5, 30]
