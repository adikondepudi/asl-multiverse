# FILE: config/v5_stage1_8hr_prod.yaml
# REWRITTEN FOR BASELINE EXPERIMENT
# Trains a generalist encoder on data with simplified physics and simple Gaussian noise.

training:
  model_class_name: "DisentangledASLNet"
  encoder_type: "physics_processor"
  hidden_sizes: [256, 128, 128]

  dropout_rate: 0.1
  weight_decay: 0.0001
  learning_rate: 0.0003
  
  batch_size: 8192
  n_ensembles: 1 
  
  # STRATEGY: See more unique data (4M) over fewer epochs to build a robust encoder.
  n_epochs: 4
  steps_per_epoch: 488 # 488 steps * 8192 batch_size = ~4M samples per epoch
  
  validation_steps_per_epoch: 25
  early_stopping_patience: 20 # Allow more patience for convergence
  early_stopping_min_delta: 0.0

  norm_type: "batch"
  transformer_d_model_focused: 32
  transformer_nhead_model: 4
  transformer_nlayers_model: 2

data:
  use_offline_dataset: true
  # --- CHANGED FOR BASELINE EXPERIMENT ---
  # Using a new directory name to ensure we train on the simplified baseline dataset.
  offline_dataset_path: "asl_offline_dataset_10M_baseline_v1"
  num_samples_to_load: 4000000 
  pld_values: [500, 1000, 1500, 2000, 2500, 3000]

simulation:
  T1_artery: 1850.0
  T_tau: 1800.0
  T2_factor: 1.0
  alpha_BS1: 1.0
  alpha_PCASL: 0.85
  alpha_VSASL: 0.56

wandb:
  # --- CHANGED FOR BASELINE EXPERIMENT ---
  # Logging to a separate project to avoid confusion with previous complex runs.
  wandb_project: "asl-multiverse-baseline-v1"
  wandb_entity: "adikondepudi"