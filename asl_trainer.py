import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
from collections import defaultdict
from torch.optim.lr_scheduler import OneCycleLR
import math
import multiprocessing as mp
from pathlib import Path
import wandb 
from sklearn.metrics import mean_absolute_error, mean_squared_error 


num_workers = mp.cpu_count()

from enhanced_asl_network import EnhancedASLNet, CustomLoss # Assuming CustomLoss needs config now
# from enhanced_simulation import RealisticASLSimulator # For type hinting

import logging
logger = logging.getLogger(__name__)
if not logger.hasHandlers():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')


class ASLNet(nn.Module):
    """Neural network for ASL parameter estimation"""

    def __init__(self, input_size: int, hidden_sizes: List[int] = [64, 32, 16]):
        super().__init__()

        # Build network layers
        layers = []
        prev_size = input_size

        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.ReLU(),
                nn.BatchNorm1d(hidden_size),
                nn.Dropout(0.1)
            ])
            prev_size = hidden_size

        # Output layer for CBF and ATT
        layers.append(nn.Linear(prev_size, 2))

        self.network = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)

class ASLDataset(Dataset):
    """Dataset for ASL signals and parameters"""

    def __init__(self, signals: np.ndarray, params: np.ndarray):
        self.signals = torch.FloatTensor(signals)
        self.params = torch.FloatTensor(params)

    def __len__(self) -> int:
        return len(self.signals)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        return self.signals[idx], self.params[idx]

class ASLTrainer:
    """Training manager for ASL parameter estimation network"""

    def __init__(self,
                 input_size: int,
                 hidden_sizes: List[int] = [64, 32, 16],
                 learning_rate: float = 1e-3,
                 batch_size: int = 32,
                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):

        self.device = device
        self.batch_size = batch_size

        # Initialize network
        self.model = ASLNet(input_size, hidden_sizes).to(device)
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        self.criterion = nn.MSELoss()

        # Track training progress
        self.train_losses = []
        self.val_losses = []

    def prepare_data(self,
                    simulator, # ASLSimulator instance
                    n_samples: int = 10000,
                    val_split: float = 0.2,
                    plds_definition: Optional[np.ndarray] = None) -> Tuple[DataLoader, DataLoader]:
        """Prepare training and validation data loaders"""
        if plds_definition is None:
            plds = np.arange(500, 3001, 500)
        else:
            plds = plds_definition

        att_values = np.arange(0, 4001, 100)
        signals_dict = simulator.generate_synthetic_data(
            plds, att_values, n_noise=n_samples, tsnr=5.0,
            cbf_val=simulator.params.CBF
        )

        num_total_instances = n_samples * len(att_values)
        X = np.zeros((num_total_instances, len(plds) * 2))

        pcasl_all = signals_dict['PCASL'].reshape(num_total_instances, len(plds))
        vsasl_all = signals_dict['VSASL'].reshape(num_total_instances, len(plds))

        X[:, :len(plds)] = pcasl_all
        X[:, len(plds):] = vsasl_all

        cbf_true_val = simulator.params.CBF
        cbf_params = np.full(num_total_instances, cbf_true_val)
        att_params = np.tile(np.repeat(att_values, 1), n_samples)
        y = np.column_stack((cbf_params, att_params))

        if num_total_instances == 0:
            raise ValueError("No data generated by simulator.prepare_data.")
        n_val = int(num_total_instances * val_split)
        if n_val == 0 and num_total_instances > 1: n_val = 1
        if n_val >= num_total_instances : n_val = num_total_instances -1 if num_total_instances > 0 else 0

        X_train, X_val = X[:-n_val], X[-n_val:]
        y_train, y_val = y[:-n_val], y[-n_val:]

        if X_train.shape[0] == 0:
            raise ValueError("Training set is empty after split.")

        train_dataset = ASLDataset(X_train, y_train)
        val_dataset = ASLDataset(X_val, y_val)

        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.batch_size if X_val.shape[0] > 0 else 1)
        return train_loader, val_loader

    def train_epoch(self, train_loader: DataLoader) -> float:
        self.model.train()
        total_loss = 0.0
        for signals, params in train_loader:
            signals, params = signals.to(self.device), params.to(self.device)
            self.optimizer.zero_grad()
            outputs = self.model(signals)
            loss = self.criterion(outputs, params)
            loss.backward()
            self.optimizer.step()
            total_loss += loss.item()
        return total_loss / len(train_loader) if len(train_loader) > 0 else 0.0

    def validate(self, val_loader: DataLoader) -> float:
        if val_loader is None or len(val_loader) == 0:
            logger.warning("Validation loader is empty or None, skipping validation.")
            return float('inf')
        self.model.eval()
        total_loss = 0.0
        with torch.no_grad():
            for signals, params in val_loader:
                signals, params = signals.to(self.device), params.to(self.device)
                outputs = self.model(signals)
                loss = self.criterion(outputs, params)
                total_loss += loss.item()
        return total_loss / len(val_loader) if len(val_loader) > 0 else float('inf')

    def train(self,
              train_loader: DataLoader,
              val_loader: DataLoader,
              n_epochs: int = 100,
              early_stopping_patience: int = 10) -> Dict[str, List[float]]:
        best_val_loss = float('inf')
        patience_counter = 0
        for epoch in range(n_epochs):
            train_loss = self.train_epoch(train_loader)
            val_loss = self.validate(val_loader)
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_model_ASLTrainer.pt')
            else:
                patience_counter += 1
            if patience_counter >= early_stopping_patience:
                logger.info(f'Early stopping triggered at epoch {epoch + 1}')
                break
            if (epoch + 1) % 10 == 0:
                logger.info(f'Epoch {epoch + 1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}')
        model_path = Path('best_model_ASLTrainer.pt')
        if model_path.exists():
            self.model.load_state_dict(torch.load(str(model_path)))
            logger.info(f"Loaded best model from {model_path}")
        else:
            logger.warning(f"Best model file {model_path} not found. Current model state will be used.")
        return {'train_losses': self.train_losses, 'val_losses': self.val_losses}

    def predict(self, signals: np.ndarray) -> np.ndarray:
        self.model.eval()
        with torch.no_grad():
            signals_tensor = torch.FloatTensor(signals).to(self.device)
            if signals_tensor.ndim == 1:
                signals_tensor = signals_tensor.unsqueeze(0)
            predictions = self.model(signals_tensor)
            return predictions.cpu().numpy()

    def evaluate_performance(self,
                           test_signals: np.ndarray,
                           true_params: np.ndarray) -> Dict[str, float]:
        predictions = self.predict(test_signals)
        mae_cbf = np.mean(np.abs(predictions[:,0] - true_params[:,0]))
        mae_att = np.mean(np.abs(predictions[:,1] - true_params[:,1]))
        rmse_cbf = np.sqrt(np.mean((predictions[:,0] - true_params[:,0])**2))
        rmse_att = np.sqrt(np.mean((predictions[:,1] - true_params[:,1])**2))
        rel_error_cbf = np.mean(np.abs(predictions[:,0] - true_params[:,0]) / np.clip(true_params[:,0], 1e-6, None))
        rel_error_att = np.mean(np.abs(predictions[:,1] - true_params[:,1]) / np.clip(true_params[:,1], 1e-6, None))
        return {'MAE_CBF': mae_cbf, 'MAE_ATT': mae_att, 'RMSE_CBF': rmse_cbf, 'RMSE_ATT': rmse_att,
                'RelError_CBF': rel_error_cbf, 'RelError_ATT': rel_error_att}


class EnhancedASLDataset(Dataset):
    def __init__(self,
                 signals: np.ndarray, # Assumed to be already normalized if per-modality norm is done upstream
                 params: np.ndarray, # Assumed to be already normalized if target normalization is done upstream
                 # Augmentation parameters
                 noise_config: Dict = {'type': 'additive_gaussian', 'std_fraction': 0.05, 'abs_std': 0.0001}, # std_fraction of signal max, or abs_std
                 dropout_range: Tuple[float, float] = (0.05, 0.15), # Dropout of PLD points
                 global_scale_range: Tuple[float, float] = (0.95, 1.05), # Simulates efficiency variations
                 baseline_shift_std_factor: float = 0.01, # Fraction of signal mean_abs for baseline shift
                 reference_signal_max_for_noise: float = 3.0 # Approx max expected NORMALIZED ASL signal for noise scaling
                ):
        self.signals = torch.FloatTensor(signals)
        self.params = torch.FloatTensor(params)
        
        self.noise_config = noise_config
        self.dropout_range = dropout_range
        self.global_scale_range = global_scale_range
        self.baseline_shift_std_factor = baseline_shift_std_factor
        self.reference_signal_max_for_noise = reference_signal_max_for_noise


    def __len__(self) -> int:
        return len(self.signals)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        signal = self.signals[idx].clone()
        param = self.params[idx].clone() # Params are already normalized if done in prepare_curriculum_data

        # 1. Parameter-Aware Noise (Phase 2, Item 2.2)
        if self.noise_config and self.noise_config.get('type') == 'additive_gaussian' and np.random.rand() < 0.5:
            # Noise std can be a fraction of a reference max signal, or an absolute std
            noise_std = self.noise_config.get('std_fraction', 0.05) * self.reference_signal_max_for_noise \
                        if 'std_fraction' in self.noise_config else self.noise_config.get('abs_std', 0.0001)
            
            if noise_std > 1e-9: # Ensure noise_std is sensible
                noise = torch.randn_like(signal) * noise_std
                signal += noise

        # 2. Dropout of PLD points (original)
        if self.dropout_range and np.random.rand() < 0.5:
            dropout_prob = np.random.uniform(*self.dropout_range)
            mask = torch.rand_like(signal) > dropout_prob
            signal *= mask

        # 3. Global Scaling (simulates efficiency perturbations - Phase 2, Item 2.2)
        if self.global_scale_range and np.random.rand() < 0.5:
            scale_factor = np.random.uniform(*self.global_scale_range)
            signal *= scale_factor
            
        # 4. Baseline Shift (original)
        if self.baseline_shift_std_factor > 0 and np.random.rand() < 0.5:
            signal_mean_abs = torch.mean(torch.abs(signal))
            if signal_mean_abs > 1e-6: # Avoid issues with all-zero signals
                shift_std = self.baseline_shift_std_factor * signal_mean_abs
                shift = torch.randn(1) * shift_std 
                signal += shift.item() # Add scalar shift to all elements

        return signal, param

class EnhancedASLTrainer:
    def __init__(self,
                 model_config: Dict, # Pass necessary params for model instantiation and loss
                 model_class, # e.g., EnhancedASLNet
                 input_size: int, # Actual input size for the model
                 # hidden_sizes: List[int], # Now part of model_config
                 learning_rate: float = 0.001,
                 weight_decay: float = 1e-5, # Added weight decay
                 batch_size: int = 256,
                 n_ensembles: int = 5,
                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
                 n_plds_for_model: Optional[int] = None, # Used for splitting PCASL/VSASL if needed
                 m0_input_feature_model: bool = False
                ):
        self.device = device
        self.batch_size = batch_size
        self.n_ensembles = n_ensembles
        self.n_plds_for_model = n_plds_for_model # Number of PLDs per modality
        self.m0_input_feature_model = m0_input_feature_model
        # self.hidden_sizes = hidden_sizes
        self.input_size_model = input_size
        self.learning_rate = learning_rate
        self.weight_decay = weight_decay # Store weight decay
        self.model_config = model_config # Store the full config for model and loss

        self.models = [model_class(**model_config).to(device) for _ in range(n_ensembles)]
        self.best_states = [None] * self.n_ensembles
        self.optimizers = [torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=self.weight_decay) for model in self.models] # Added weight_decay
        self.schedulers = [] # To be initialized in prepare_curriculum_data
        self.custom_loss_fn = CustomLoss( # Initialize with config
            w_cbf=model_config.get('loss_weight_cbf', 1.0),
            w_att=model_config.get('loss_weight_att', 1.0),
            log_var_reg_lambda=model_config.get('loss_log_var_reg_lambda', 0.0)
        )
        self.train_losses = defaultdict(list)
        self.val_metrics = defaultdict(list)
        self.global_step = 0
        self.norm_stats = None # Will be populated by prepare_curriculum_data

    def prepare_curriculum_data(self,
                                simulator, # RealisticASLSimulator instance
                                plds: np.ndarray,
                                n_training_subjects: int = 10000,
                                val_split: float = 0.2,
                                curriculum_att_ranges_config: Optional[List[Tuple[float, float, str]]] = None,
                                training_conditions_config: Optional[List[str]] = None,
                                training_noise_levels_config: Optional[List[float]] = None,
                                n_epochs_for_scheduler: int = 200,
                                include_m0_in_data: bool = False,
                                dataset_aug_config: Optional[Dict] = None,
                                precomputed_dataset: Optional[Dict] = None # <-- NEW ARGUMENT
                                ) -> Tuple[List[DataLoader], List[Optional[DataLoader]], Optional[Dict]]:
        if precomputed_dataset:
            logger.info("Using pre-computed dataset for training data preparation.")
            raw_dataset = precomputed_dataset
        else:
            # This is the original data generation logic, which now serves as a fallback.
            logger.info("No pre-computed dataset provided. Generating diverse dataset now...")
            conditions = training_conditions_config if training_conditions_config is not None else ['healthy', 'stroke', 'tumor', 'elderly']
            noise_levels = training_noise_levels_config if training_noise_levels_config is not None else [3.0, 5.0, 10.0, 15.0]
            logger.info(f"Generating diverse training data: {n_training_subjects} base subjects, cond: {conditions}, SNRs: {noise_levels}")
            raw_dataset = simulator.generate_diverse_dataset(
                plds=plds, n_subjects=n_training_subjects, conditions=conditions, noise_levels=noise_levels
            )
        
        if plds is None: plds = np.arange(500, 3001, 500)
        num_plds_per_modality = len(plds) # Assuming plds refers to one modality's PLDs

        conditions = training_conditions_config if training_conditions_config is not None else ['healthy', 'stroke', 'tumor', 'elderly']
        noise_levels = training_noise_levels_config if training_noise_levels_config is not None else [3.0, 5.0, 10.0, 15.0]
        logger.info(f"Generating diverse training data: {n_training_subjects} base subjects, cond: {conditions}, SNRs: {noise_levels}")

        raw_dataset = simulator.generate_diverse_dataset(
            plds=plds, n_subjects=n_training_subjects, conditions=conditions, noise_levels=noise_levels
        )
        X_all_asl_raw, y_all_raw = raw_dataset['signals'], raw_dataset['parameters'] # X_all_asl_raw is (N, num_plds*2)

        # --- Phase 2, Item 2.1: Per-Modality Input Normalization & Target Normalization ---
        n_total_samples_raw = X_all_asl_raw.shape[0]
        if n_total_samples_raw == 0: raise ValueError("No data generated by simulator.")
        
        # Split for normalization stat calculation (on training part only)
        indices_raw = np.random.permutation(n_total_samples_raw)
        n_val_raw = int(n_total_samples_raw * val_split)
        if n_val_raw == 0 and n_total_samples_raw > 1: n_val_raw = 1
        if n_val_raw >= n_total_samples_raw: n_val_raw = n_total_samples_raw -1 if n_total_samples_raw > 0 else 0

        train_idx_raw, val_idx_raw = indices_raw[:-n_val_raw], indices_raw[-n_val_raw:]
        X_train_raw_asl, X_val_raw_asl = X_all_asl_raw[train_idx_raw], X_all_asl_raw[val_idx_raw]
        y_train_raw, y_val_raw = y_all_raw[train_idx_raw], y_all_raw[val_idx_raw]
        
        norm_stats = { # For feature-wise normalization
            'pcasl_mean': np.zeros(num_plds_per_modality), 'pcasl_std': np.ones(num_plds_per_modality),
            'vsasl_mean': np.zeros(num_plds_per_modality), 'vsasl_std': np.ones(num_plds_per_modality),
            'm0_mean': np.array([0.0]), 'm0_std': np.array([1.0]), # Defaults for M0
            'y_mean_cbf': 0.0, 'y_std_cbf': 1.0, # Defaults for y_cbf
            'y_mean_att': 0.0, 'y_std_att': 1.0  # Defaults for y_att
        }

        if X_train_raw_asl.shape[0] > 0 :
            # PCASL part: first num_plds_per_modality columns
            pcasl_train_signals = X_train_raw_asl[:, :num_plds_per_modality]
            norm_stats['pcasl_mean'] = np.mean(pcasl_train_signals, axis=0)
            norm_stats['pcasl_std'] = np.std(pcasl_train_signals, axis=0)
            norm_stats['pcasl_std'][norm_stats['pcasl_std'] < 1e-6] = 1.0 # Avoid division by zero

            # VSASL part: next num_plds_per_modality columns
            vsasl_train_signals = X_train_raw_asl[:, num_plds_per_modality : num_plds_per_modality*2]
            norm_stats['vsasl_mean'] = np.mean(vsasl_train_signals, axis=0)
            norm_stats['vsasl_std'] = np.std(vsasl_train_signals, axis=0)
            norm_stats['vsasl_std'][norm_stats['vsasl_std'] < 1e-6] = 1.0
            
            # Target (y) normalization stats from y_train_raw
            norm_stats['y_mean_cbf'] = np.mean(y_train_raw[:, 0])
            norm_stats['y_std_cbf'] = np.std(y_train_raw[:, 0])
            if norm_stats['y_std_cbf'] < 1e-6: norm_stats['y_std_cbf'] = 1.0
            
            norm_stats['y_mean_att'] = np.mean(y_train_raw[:, 1])
            norm_stats['y_std_att'] = np.std(y_train_raw[:, 1])
            if norm_stats['y_std_att'] < 1e-6: norm_stats['y_std_att'] = 1.0
        else:
            logger.warning("Raw training set for normalization stats is empty. Using default unit stats for X and Y.")


        # Apply normalization to the entire X_all_asl_raw
        X_all_asl_normalized = np.zeros_like(X_all_asl_raw)
        X_all_asl_normalized[:, :num_plds_per_modality] = \
            (X_all_asl_raw[:, :num_plds_per_modality] - norm_stats['pcasl_mean']) / norm_stats['pcasl_std']
        X_all_asl_normalized[:, num_plds_per_modality : num_plds_per_modality*2] = \
            (X_all_asl_raw[:, num_plds_per_modality : num_plds_per_modality*2] - norm_stats['vsasl_mean']) / norm_stats['vsasl_std']

        # Apply normalization to y_all_raw
        y_all_normalized = np.zeros_like(y_all_raw)
        y_all_normalized[:, 0] = (y_all_raw[:, 0] - norm_stats['y_mean_cbf']) / norm_stats['y_std_cbf']
        y_all_normalized[:, 1] = (y_all_raw[:, 1] - norm_stats['y_mean_att']) / norm_stats['y_std_att']

        X_all_processed = X_all_asl_normalized
        if include_m0_in_data: # Assuming M0 comes from simulator or is dummied here
            m0_dummy_values = np.random.normal(1.0, 0.1, size=(X_all_asl_raw.shape[0], 1)) # Example M0
            if X_train_raw_asl.shape[0] > 0 :
                m0_train_values = m0_dummy_values[train_idx_raw]
                norm_stats['m0_mean'] = np.mean(m0_train_values, axis=0)
                norm_stats['m0_std'] = np.std(m0_train_values, axis=0)
                norm_stats['m0_std'][norm_stats['m0_std'] < 1e-6] = 1.0

            m0_normalized = (m0_dummy_values - norm_stats['m0_mean']) / norm_stats['m0_std']
            X_all_processed = np.concatenate((X_all_asl_normalized, m0_normalized), axis=1)
            logger.info("Included and normalized (dummy) M0 feature.")
        # --- End Normalization ---
        self.norm_stats = norm_stats # Store norm_stats in trainer

        logger.info(f"Total generated diverse samples for training/validation: {X_all_processed.shape[0]}")
        
        # Use the same train/val split indices as used for stats calculation
        # And use the normalized versions of X and y
        X_train, y_train_norm = X_all_processed[train_idx_raw], y_all_normalized[train_idx_raw]
        X_val, y_val_norm = X_all_processed[val_idx_raw], y_all_normalized[val_idx_raw]

        logger.info(f"Training samples: {X_train.shape[0]}, Validation samples: {X_val.shape[0]}")
        if X_train.shape[0] == 0: raise ValueError("Training set is empty after split and normalization.")

        # Curriculum stages definition
        if curriculum_att_ranges_config is None:
            min_att_sim_raw, max_att_sim_raw = simulator.physio_var.att_range # Raw ATT values
            curriculum_stages_def = [(min_att_sim_raw, 1500.0), (1500.0, 2500.0), (2500.0, max_att_sim_raw)]
        else:
            curriculum_stages_def = [(r[0], r[1]) for r in curriculum_att_ranges_config]

        train_loaders = []
        val_loaders = [] # For stage-specific validation loaders
        default_dataset_aug_config = {
            'noise_config': {'type': 'additive_gaussian', 'std_fraction': 0.05, 'abs_std': 0.0001},
            'dropout_range': (0.05, 0.15),
            'global_scale_range': (0.95, 1.05),
            'baseline_shift_std_factor': 0.01,
            'reference_signal_max_for_noise': 3.0 # Adjusted for normalized signals
        }
        if dataset_aug_config: default_dataset_aug_config.update(dataset_aug_config)

        val_aug_config_minimal = default_dataset_aug_config.copy()
        val_aug_config_minimal['noise_config'] = {} # No noise for val
        val_aug_config_minimal['dropout_range'] = None # No dropout


        for i, (att_min_stage_raw, att_max_stage_raw) in enumerate(curriculum_stages_def):
            # Masking on y_train_raw (unnormalized ATT) for stage definition
            train_mask_stage = (y_train_raw[:, 1] >= att_min_stage_raw) & (y_train_raw[:, 1] <= att_max_stage_raw)
            stage_X_train, stage_y_train_norm = X_train[train_mask_stage], y_train_norm[train_mask_stage]
            
            if len(stage_X_train) == 0:
                logger.warning(f"Curriculum training stage {i+1} (ATT {att_min_stage_raw}-{att_max_stage_raw}ms) has no samples. Skipping train loader.")
                train_loaders.append(DataLoader(EnhancedASLDataset(np.array([]), np.array([]), **default_dataset_aug_config), batch_size=self.batch_size)) # Empty loader
            else:
                logger.info(f"Curriculum training stage {i+1} (ATT {att_min_stage_raw}-{att_max_stage_raw}ms): {len(stage_X_train)} samples.")
                att_for_weights_raw = y_train_raw[train_mask_stage, 1] # Use raw ATT for weighting
                att_for_weights_raw_clipped = np.clip(att_for_weights_raw, a_min=100.0, a_max=None)
                weights = np.exp(-att_for_weights_raw_clipped / 2000.0)
                sampler = None
                if np.sum(weights) > 1e-9 and np.all(np.isfinite(weights)) and len(weights) > 0:
                    try: sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)
                    except RuntimeError as e: logger.warning(f"Failed to create WeightedRandomSampler for train stage {i+1}: {e}. Using uniform.")
                else: logger.warning(f"Invalid weights in curriculum train stage {i+1}. Using uniform.")

                dataset = EnhancedASLDataset(stage_X_train, stage_y_train_norm, **default_dataset_aug_config)
                loader = DataLoader(dataset, batch_size=self.batch_size, sampler=sampler,
                                    num_workers=max(0,num_workers-1), pin_memory=True, drop_last=(len(stage_X_train) > self.batch_size))
                train_loaders.append(loader)

            # Create corresponding validation loader for this stage
            if X_val.shape[0] > 0:
                val_mask_stage = (y_val_raw[:, 1] >= att_min_stage_raw) & (y_val_raw[:, 1] <= att_max_stage_raw)
                stage_X_val, stage_y_val_norm = X_val[val_mask_stage], y_val_norm[val_mask_stage]

                if len(stage_X_val) == 0:
                    logger.warning(f"Curriculum validation stage {i+1} (ATT {att_min_stage_raw}-{att_max_stage_raw}ms) has no samples. Appending empty loader.")
                    empty_val_dataset = EnhancedASLDataset(np.array([]), np.array([]), **val_aug_config_minimal)
                    val_loaders.append(DataLoader(empty_val_dataset, batch_size=self.batch_size))
                else:
                    logger.info(f"Curriculum validation stage {i+1} (ATT {att_min_stage_raw}-{att_max_stage_raw}ms): {len(stage_X_val)} samples.")
                    val_dataset_stage = EnhancedASLDataset(stage_X_val, stage_y_val_norm, **val_aug_config_minimal)
                    val_loader_stage = DataLoader(val_dataset_stage, batch_size=self.batch_size,
                                                num_workers=max(0,num_workers-1), pin_memory=True, drop_last=False)
                    val_loaders.append(val_loader_stage)
            else: # No validation set at all for this stage
                logger.warning(f"No validation data available for curriculum stage {i+1}. Appending empty loader.")
                empty_val_dataset = EnhancedASLDataset(np.array([]), np.array([]), **val_aug_config_minimal)
                val_loaders.append(DataLoader(empty_val_dataset, batch_size=self.batch_size))


        if not train_loaders: logger.error("No training data loaders created.")
        if not val_loaders: logger.warning("No validation data loaders created.")
        
        # Add curriculum sanity check logging
        logger.info("--- CURRICULUM SANITY CHECK ---")
        for i in range(len(train_loaders)):
            train_samples = len(train_loaders[i].dataset)
            val_samples = len(val_loaders[i].dataset) if i < len(val_loaders) else 0
            logger.info(f"  Stage {i+1}: Train samples: {train_samples}, Val samples: {val_samples}")
        logger.info("-----------------------------")
        
        # Initialize schedulers
        self.schedulers = []
        if train_loaders:
            # Assuming OneCycleLR should span all epochs across all stages.
            # If stages have vastly different numbers of batches, this might not be ideal.
            # For now, total_steps_per_epoch is sum over all stages' first epoch.
            total_steps_per_stage_epoch = sum(len(loader) for loader in train_loaders) 
            if total_steps_per_stage_epoch > 0 :
                # If n_epochs is per stage, total steps for scheduler should be based on total epochs for one pass through curriculum
                total_scheduler_steps = total_steps_per_stage_epoch * n_epochs_for_scheduler * len(train_loaders) # This seems too large
                # The OneCycleLR is usually per "full training run".
                # If curriculum is sequential, then perhaps total_steps = total batches in ONE pass through all stages * n_epochs_per_stage.
                # Or if each stage is trained fully, then total_steps = batches_in_stage * n_epochs_per_stage, and scheduler resets.
                # Given early stopping reset, let's assume scheduler runs over total epochs (num_stages * n_epochs_per_stage)
                # Corrected total steps for OneCycleLR:
                # total_steps = sum(len(loader) for loader in train_loaders) * n_epochs_for_scheduler
                # This assumes n_epochs_for_scheduler is TOTAL epochs, not per stage.
                # If n_epochs_for_scheduler IS per stage, and stages run sequentially:
                total_steps_overall = 0
                for loader in train_loaders:
                    total_steps_overall += len(loader) * n_epochs_for_scheduler

                if total_steps_overall > 0:
                    for opt in self.optimizers:
                        current_lr = opt.param_groups[0]['lr'] if opt.param_groups else self.learning_rate
                        self.schedulers.append(OneCycleLR(opt, max_lr=current_lr, total_steps=total_steps_overall))
                else:
                    logger.warning("Total steps for scheduler is 0.")

            else: logger.warning("Total steps per epoch is 0 for scheduler.")
        else: logger.warning("No training loaders for scheduler.")
        
        return train_loaders, val_loaders, norm_stats # Return norm_stats

    def train_ensemble(self,
                   train_loaders: List[DataLoader],
                   val_loaders: List[Optional[DataLoader]], # Updated signature
                   n_epochs: int = 200,
                   early_stopping_patience: int = 20) -> Dict[str, any]:
        
        histories = defaultdict(lambda: defaultdict(list))
        self.global_step = 0

        if not train_loaders:
            logger.error("train_loaders is empty. Aborting training.")
            return {'final_mean_train_loss': float('nan'), 'final_mean_val_loss': float('nan'), 'all_histories': histories}

        for stage_idx, train_loader in enumerate(train_loaders):
            current_val_loader = val_loaders[stage_idx] if stage_idx < len(val_loaders) else None
            
            # Add stage start logging
            logger.info(f"--- STAGE {stage_idx+1} START ---")
            logger.info(f"  Resetting early stopping. Best val losses set to infinity.")
            if current_val_loader:
                logger.info(f"  Using validation loader with {len(current_val_loader)} batches.")
            else:
                logger.info("  No validation loader for this stage.")
            
            logger.info(f"\nStarting curriculum stage {stage_idx + 1}/{len(train_loaders)} with {len(train_loader)} train batches.")
            if len(train_loader) == 0:
                logger.warning(f"Skipping empty curriculum training stage {stage_idx + 1}.")
                continue
            
            # Reset early stopping state at the beginning of each stage
            logger.info(f"Resetting early stopping state for Stage {stage_idx+1}.")
            best_val_losses_stage = [float('inf')] * self.n_ensembles # Store best val loss *for this stage*
            patience_counters_stage = [0] * self.n_ensembles      # Patience for *this stage*
            # self.best_states (overall best parameters) are NOT reset. They are updated if current model is better.

            for epoch in range(n_epochs): # n_epochs is per stage
                epoch_train_losses_all_models, epoch_val_metrics_all_models = [], []
                
                for model_idx in range(self.n_ensembles):
                    train_loss_epoch = self._train_epoch(self.models[model_idx], train_loader, 
                                                       self.optimizers[model_idx], 
                                                       self.schedulers[model_idx] if self.schedulers else None, 
                                                       epoch)
                    epoch_train_losses_all_models.append(train_loss_epoch)
                    histories[model_idx][f'train_losses_stage_{stage_idx}'].append(train_loss_epoch)
                    
                    if current_val_loader:
                        val_metrics_dict = self._validate(self.models[model_idx], current_val_loader, epoch)
                        epoch_val_metrics_all_models.append(val_metrics_dict)
                        histories[model_idx][f'val_metrics_stage_{stage_idx}'].append(val_metrics_dict)
                        
                        # Add validation loss logging for current stage
                        val_loss_for_es = val_metrics_dict.get('val_loss', float('inf'))
                        logger.info(f"  Epoch {epoch+1}, Model {model_idx}, Stage {stage_idx+1} Val Loss: {val_loss_for_es:.4f}")
                        
                        # Early stopping and best model tracking for this stage and overall
                        if val_loss_for_es < best_val_losses_stage[model_idx]:
                            best_val_losses_stage[model_idx] = val_loss_for_es
                            patience_counters_stage[model_idx] = 0
                            # Update overall best model state if this stage's model is better
                            # The self.best_states should store the state dict of the model that achieved the best validation loss *so far across all stages*.
                            # This requires comparing val_loss_for_es with a global best for this model.
                            # Let's maintain a global best_val_losses for self.best_states update.
                            # Initialize self.overall_best_val_losses if not present
                            if not hasattr(self, 'overall_best_val_losses'):
                                self.overall_best_val_losses = [float('inf')] * self.n_ensembles
                            
                            if val_loss_for_es < self.overall_best_val_losses[model_idx]:
                                self.overall_best_val_losses[model_idx] = val_loss_for_es
                                self.best_states[model_idx] = self.models[model_idx].state_dict() # Save best overall state
                                logger.debug(f"Model {model_idx} new overall best state saved (Val loss: {val_loss_for_es:.4f})")

                        else:
                            patience_counters_stage[model_idx] += 1
                    else: # No validation loader for this stage or empty
                        histories[model_idx]['val_metrics_stage_'+str(stage_idx)].append({'val_loss': float('inf')}) 


                # Log mean metrics for the epoch across active models for this stage
                if wandb.run:
                    mean_epoch_train_loss = np.nanmean(epoch_train_losses_all_models) if epoch_train_losses_all_models else float('nan')
                    wandb.log({f'Epoch_Stage{stage_idx}/Mean_Train_Loss': mean_epoch_train_loss, 'epoch_global': self.global_step, 'epoch_stage': epoch})
                    if current_val_loader and len(current_val_loader) > 0 and epoch_val_metrics_all_models:
                        # Aggregate validation metrics from the list of dicts
                        epoch_val_metrics_agg = defaultdict(list)
                        for model_metrics in epoch_val_metrics_all_models:
                            for metric_name, value in model_metrics.items():
                                epoch_val_metrics_agg[metric_name].append(value)
                        
                        # Now log the aggregated metrics
                        for metric_name, values_list in epoch_val_metrics_agg.items():
                            mean_val_metric = np.nanmean(values_list) if values_list else float('nan')
                            wandb.log({f'Epoch_Stage{stage_idx}/Mean_Val_{metric_name.capitalize()}': mean_val_metric, 'epoch_global': self.global_step, 'epoch_stage': epoch})

                # Check if all active models have early stopped IN THIS STAGE
                if sum(1 for p_count in patience_counters_stage if p_count < early_stopping_patience) == 0 and epoch > 0 : 
                    logger.info(f"All active models early stopped within stage {stage_idx+1}, epoch {epoch+1}. Moving to next stage.")
                    break 

                if (epoch + 1) % 10 == 0:
                    active_train_losses = [histories[i][f'train_losses_stage_{stage_idx}'][-1] for i in range(self.n_ensembles) if patience_counters_stage[i] < early_stopping_patience]
                    active_val_losses_stage = [histories[i][f'val_metrics_stage_{stage_idx}'][-1]['val_loss'] for i in range(self.n_ensembles) if histories[i].get(f'val_metrics_stage_{stage_idx}') and patience_counters_stage[i] < early_stopping_patience]
                    
                    mean_train_loss_console = np.nanmean(active_train_losses) if active_train_losses else float('nan')
                    mean_val_loss_console_stage = np.nanmean(active_val_losses_stage) if active_val_losses_stage else float('nan')
                    logger.info(f"Stage {stage_idx+1}, Epoch {epoch + 1}/{n_epochs}: Mean Active Train Loss = {mean_train_loss_console:.6f}, Mean Active Val Loss (Stage) = {mean_val_loss_console_stage:.6f}")
        
        # After all stages, load best OVERALL states for all models
        if not hasattr(self, 'overall_best_val_losses'): # ensure it exists if no validation was run
            self.overall_best_val_losses = [float('inf')] * self.n_ensembles

        for model_idx, state in enumerate(self.best_states):
            if state is not None:
                self.models[model_idx].load_state_dict(state)
                logger.info(f"Loaded best overall state for model {model_idx} (Overall Val Loss: {self.overall_best_val_losses[model_idx]:.4f})")
            else: 
                logger.warning(f"No best overall state found for model {model_idx}. Using final state from last trained stage.")

        final_train_losses_list_overall = []
        for i in range(self.n_ensembles):
            model_train_losses = []
            for s_idx in range(len(train_loaders)): # Iterate through stages
                key = f'train_losses_stage_{s_idx}'
                if key in histories[i] and histories[i][key]:
                    model_train_losses.extend(histories[i][key])
            if model_train_losses:
                final_train_losses_list_overall.append(np.nanmean(model_train_losses))

        final_val_losses_list_overall = [self.overall_best_val_losses[i] for i in range(self.n_ensembles) if self.overall_best_val_losses[i] != float('inf')]
        
        final_mean_train_loss_overall = np.nanmean(final_train_losses_list_overall) if final_train_losses_list_overall else float('nan')
        final_mean_val_loss_overall = np.nanmean(final_val_losses_list_overall) if final_val_losses_list_overall else float('nan')

        if wandb.run:
            wandb.summary['final_mean_train_loss_overall'] = final_mean_train_loss_overall
            wandb.summary['final_mean_val_loss_overall'] = final_mean_val_loss_overall

        return {'final_mean_train_loss': final_mean_train_loss_overall, 'final_mean_val_loss': final_mean_val_loss_overall, 'all_histories': histories}

    def _train_epoch(self, model, train_loader, optimizer, scheduler, current_global_epoch: int) -> float:
        model.train(); total_loss = 0.0
        for signals, params_norm in train_loader: # params_norm are normalized targets
            signals, params_norm = signals.to(self.device), params_norm.to(self.device)
            optimizer.zero_grad()
            cbf_mean_norm, att_mean_norm, cbf_log_var, att_log_var = model(signals) # Model predicts normalized
            # Loss function expects normalized predictions and normalized targets
            loss = self.custom_loss_fn(cbf_mean_norm, att_mean_norm, params_norm[:, 0:1], params_norm[:, 1:2], 
                                       cbf_log_var, att_log_var, current_global_epoch)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            if scheduler: scheduler.step() 
            total_loss += loss.item()
        return total_loss / len(train_loader) if len(train_loader) > 0 else 0.0

    def _validate(self, model, val_loader, current_global_epoch: int) -> Dict[str, float]:
        model.eval(); total_loss_val = 0.0
        all_cbf_preds_norm, all_att_preds_norm = [], []
        all_cbf_trues_norm, all_att_trues_norm = [], []
        all_cbf_log_vars, all_att_log_vars = [], []

        with torch.no_grad():
            for signals, params_norm in val_loader: # params_norm are normalized targets
                signals, params_norm = signals.to(self.device), params_norm.to(self.device)
                cbf_mean_norm, att_mean_norm, cbf_log_var, att_log_var = model(signals) # Model predicts normalized
                # Loss function expects normalized predictions and normalized targets
                loss = self.custom_loss_fn(cbf_mean_norm, att_mean_norm, params_norm[:, 0:1], params_norm[:, 1:2], 
                                           cbf_log_var, att_log_var, current_global_epoch)
                total_loss_val += loss.item()
                all_cbf_preds_norm.append(cbf_mean_norm.cpu()); all_att_preds_norm.append(att_mean_norm.cpu())
                all_cbf_trues_norm.append(params_norm[:, 0:1].cpu()); all_att_trues_norm.append(params_norm[:, 1:2].cpu())
                all_cbf_log_vars.append(cbf_log_var.cpu()); all_att_log_vars.append(att_log_var.cpu())
        
        avg_loss_val = total_loss_val / len(val_loader) if len(val_loader) > 0 else float('inf')
        metrics_dict = {'val_loss': avg_loss_val}

        if all_cbf_preds_norm and self.norm_stats: # If there were batches and norm_stats exist
            y_mean_cbf = self.norm_stats.get('y_mean_cbf', 0.0)
            y_std_cbf = self.norm_stats.get('y_std_cbf', 1.0)
            y_mean_att = self.norm_stats.get('y_mean_att', 0.0)
            y_std_att = self.norm_stats.get('y_std_att', 1.0)

            cbf_preds_norm_cat = torch.cat(all_cbf_preds_norm).numpy().squeeze()
            att_preds_norm_cat = torch.cat(all_att_preds_norm).numpy().squeeze()
            cbf_trues_norm_cat = torch.cat(all_cbf_trues_norm).numpy().squeeze()
            att_trues_norm_cat = torch.cat(all_att_trues_norm).numpy().squeeze()

            # De-normalize for metrics
            cbf_preds_denorm = cbf_preds_norm_cat * y_std_cbf + y_mean_cbf
            att_preds_denorm = att_preds_norm_cat * y_std_att + y_mean_att
            cbf_trues_denorm = cbf_trues_norm_cat * y_std_cbf + y_mean_cbf
            att_trues_denorm = att_trues_norm_cat * y_std_att + y_mean_att
            
            if len(cbf_preds_denorm) > 0 : 
                metrics_dict['cbf_mae'] = mean_absolute_error(cbf_trues_denorm, cbf_preds_denorm)
                metrics_dict['cbf_rmse'] = np.sqrt(mean_squared_error(cbf_trues_denorm, cbf_preds_denorm))
                metrics_dict['att_mae'] = mean_absolute_error(att_trues_denorm, att_preds_denorm)
                metrics_dict['att_rmse'] = np.sqrt(mean_squared_error(att_trues_denorm, att_preds_denorm))

                cbf_log_vars_cat = torch.cat(all_cbf_log_vars).numpy().squeeze()
                att_log_vars_cat = torch.cat(all_att_log_vars).numpy().squeeze()
                metrics_dict['mean_cbf_log_var'] = np.mean(cbf_log_vars_cat) # Log_var is scale-invariant to linear transforms of target
                metrics_dict['mean_att_log_var'] = np.mean(att_log_vars_cat) # So, no de-norm needed for log_var itself
        return metrics_dict

    def predict(self, signals: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        # Note: signals here are assumed to be ALREADY NORMALIZED if normalization is used.
        # This is handled by the caller (e.g. ComprehensiveComparison, ClinicalValidator)
        signals_tensor = torch.FloatTensor(signals).to(self.device)
        if signals_tensor.ndim == 1: signals_tensor = signals_tensor.unsqueeze(0)
        
        all_cbf_means_norm_list, all_att_means_norm_list = [], []
        all_cbf_aleatoric_vars_list, all_att_aleatoric_vars_list = [], [] # Variance is not directly normalized

        for model in self.models:
            model.eval()
            with torch.no_grad():
                cbf_mean_norm, att_mean_norm, cbf_log_var, att_log_var = model(signals_tensor) # Model predicts normalized
                all_cbf_means_norm_list.append(cbf_mean_norm.cpu().numpy())
                all_att_means_norm_list.append(att_mean_norm.cpu().numpy())
                all_cbf_aleatoric_vars_list.append(torch.exp(cbf_log_var).cpu().numpy()) # Aleatoric var of normalized pred
                all_att_aleatoric_vars_list.append(torch.exp(att_log_var).cpu().numpy()) # Aleatoric var of normalized pred
        
        if signals_tensor.shape[0] == 1: # Single sample prediction
            all_cbf_means_norm_np = np.array(all_cbf_means_norm_list).squeeze() 
            all_att_means_norm_np = np.array(all_att_means_norm_list).squeeze() 
            all_cbf_aleatoric_vars_np = np.array(all_cbf_aleatoric_vars_list).squeeze() 
            all_att_aleatoric_vars_np = np.array(all_att_aleatoric_vars_list).squeeze() 
            
            ensemble_cbf_mean_norm = np.mean(all_cbf_means_norm_np)
            ensemble_att_mean_norm = np.mean(all_att_means_norm_np)
            mean_aleatoric_cbf_var_norm = np.mean(all_cbf_aleatoric_vars_np) # Avg of variances of normalized preds
            mean_aleatoric_att_var_norm = np.mean(all_att_aleatoric_vars_np)
            epistemic_cbf_var_norm = np.var(all_cbf_means_norm_np) if self.n_ensembles > 1 else 0.0 # Variance of normalized means
            epistemic_att_var_norm = np.var(all_att_means_norm_np) if self.n_ensembles > 1 else 0.0

        else: # Batch prediction
            all_cbf_means_norm_np = np.concatenate(all_cbf_means_norm_list, axis=1) 
            all_att_means_norm_np = np.concatenate(all_att_means_norm_list, axis=1) 
            all_cbf_aleatoric_vars_np = np.concatenate(all_cbf_aleatoric_vars_list, axis=1) 
            all_att_aleatoric_vars_np = np.concatenate(all_att_aleatoric_vars_list, axis=1) 

            ensemble_cbf_mean_norm = np.mean(all_cbf_means_norm_np, axis=1)
            ensemble_att_mean_norm = np.mean(all_att_means_norm_np, axis=1)
            mean_aleatoric_cbf_var_norm = np.mean(all_cbf_aleatoric_vars_np, axis=1)
            mean_aleatoric_att_var_norm = np.mean(all_att_aleatoric_vars_np, axis=1)
            epistemic_cbf_var_norm = np.var(all_cbf_means_norm_np, axis=1) if self.n_ensembles > 1 else np.zeros_like(ensemble_cbf_mean_norm)
            epistemic_att_var_norm = np.var(all_att_means_norm_np, axis=1) if self.n_ensembles > 1 else np.zeros_like(ensemble_att_mean_norm)

        # De-normalize means and stds
        y_mean_cbf, y_std_cbf, y_mean_att, y_std_att = 0.0, 1.0, 0.0, 1.0 # Defaults
        if self.norm_stats:
            y_mean_cbf = self.norm_stats.get('y_mean_cbf', 0.0)
            y_std_cbf = self.norm_stats.get('y_std_cbf', 1.0)
            y_mean_att = self.norm_stats.get('y_mean_att', 0.0)
            y_std_att = self.norm_stats.get('y_std_att', 1.0)

        ensemble_cbf_mean_denorm = ensemble_cbf_mean_norm * y_std_cbf + y_mean_cbf
        ensemble_att_mean_denorm = ensemble_att_mean_norm * y_std_att + y_mean_att
        
        # De-normalize variances: Var(aX+b) = a^2 Var(X)
        # Total variance of the *normalized* prediction
        total_cbf_var_norm = mean_aleatoric_cbf_var_norm + epistemic_cbf_var_norm
        total_att_var_norm = mean_aleatoric_att_var_norm + epistemic_att_var_norm
        
        # Total variance of the *de-normalized* prediction
        total_cbf_var_denorm = total_cbf_var_norm * (y_std_cbf**2)
        total_att_var_denorm = total_att_var_norm * (y_std_att**2)
        
        total_cbf_std_denorm = np.sqrt(np.maximum(total_cbf_var_denorm, 0)) 
        total_att_std_denorm = np.sqrt(np.maximum(total_att_var_denorm, 0))
        
        return ensemble_cbf_mean_denorm, ensemble_att_mean_denorm, total_cbf_std_denorm, total_att_std_denorm