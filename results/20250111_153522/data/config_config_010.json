{
    "hidden_sizes": [
        256,
        128,
        64
    ],
    "activation": "relu",
    "use_batch_norm": true,
    "dropout_rate": 0.1,
    "learning_rate": 0.0001,
    "batch_size": 256,
    "n_samples": 5000,
    "epochs": 100,
    "scheduler": "plateau",
    "use_curriculum": true
}